{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Z-dzLnxqiJK6B5de5osWnELx-H5Ftq0c",
      "authorship_tag": "ABX9TyP4UOW+UVqMHMGRYFhPYWCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ixiondbz/CSE499/blob/main/NEW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UqOA1MxA8npn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d9214c-1c5e-44b4-a40c-92bb2278b271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=f8f93763d28d3011e5a729be997ad474cde3acea668705b4793d8cb4f9c8f918\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n",
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 66925, done.\u001b[K\n",
            "remote: Counting objects: 100% (1986/1986), done.\u001b[K\n",
            "remote: Compressing objects: 100% (209/209), done.\u001b[K\n",
            "remote: Total 66925 (delta 1783), reused 1935 (delta 1767), pack-reused 64939\u001b[K\n",
            "Receiving objects: 100% (66925/66925), 126.37 MiB | 11.09 MiB/s, done.\n",
            "Resolving deltas: 100% (54906/54906), done.\n",
            "/content/vision\n",
            "Note: checking out 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at be376084d version check against PyTorch's CUDA version\n",
            "/content\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libjs-jquery libopenslide0 python-asn1crypto\n",
            "  python-blinker python-cffi-backend python-click python-colorama\n",
            "  python-cryptography python-enum34 python-flask python-idna python-ipaddress\n",
            "  python-itsdangerous python-jinja2 python-markupsafe\n",
            "  python-openslide-examples python-openssl python-pkg-resources\n",
            "  python-pyinotify python-simplejson python-six python-werkzeug\n",
            "  python3-olefile python3-pil\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd python-blinker-doc python-cryptography-doc\n",
            "  python-cryptography-vectors python-enum34-doc python-flask-doc\n",
            "  python-jinja2-doc python-openssl-doc python-openssl-dbg python-setuptools\n",
            "  python-pyinotify-doc ipython python-genshi python-lxml python-greenlet\n",
            "  python-redis python-pylibmc | python-memcache python-termcolor\n",
            "  python-watchdog python-werkzeug-doc python-pil-doc python3-pil-dbg\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libjs-jquery libopenslide0 python-asn1crypto\n",
            "  python-blinker python-cffi-backend python-click python-colorama\n",
            "  python-cryptography python-enum34 python-flask python-idna python-ipaddress\n",
            "  python-itsdangerous python-jinja2 python-markupsafe\n",
            "  python-openslide-examples python-openssl python-pkg-resources\n",
            "  python-pyinotify python-simplejson python-six python-werkzeug\n",
            "  python3-olefile python3-openslide python3-pil\n",
            "0 upgraded, 26 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,997 kB of archives.\n",
            "After this operation, 9,740 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-blinker all 1.4+dfsg1-0.1 [13.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-colorama all 0.3.7-1 [22.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-click all 6.7-3 [56.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-itsdangerous all 0.24+dfsg1-2 [11.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-markupsafe amd64 1.0-1build1 [13.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-jinja2 all 2.10-1ubuntu0.18.04.1 [94.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-werkzeug all 0.14.1+dfsg1-1ubuntu0.1 [174 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-flask all 0.12.2-3ubuntu0.1 [62.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.6 [330 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-openslide amd64 1.1.1-2ubuntu4 [16.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-openslide-examples all 1.1.1-2ubuntu4 [168 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-openssl all 17.5.0-1ubuntu1 [41.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pyinotify all 0.9.6-1 [24.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-simplejson amd64 3.13.2-1 [61.2 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n",
            "Fetched 1,997 kB in 3s (789 kB/s)\n",
            "Selecting previously unselected package javascript-common.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../00-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../01-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libopenslide0.\n",
            "Preparing to unpack .../02-libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-blinker.\n",
            "Preparing to unpack .../04-python-blinker_1.4+dfsg1-0.1_all.deb ...\n",
            "Unpacking python-blinker (1.4+dfsg1-0.1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../05-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-colorama.\n",
            "Preparing to unpack .../06-python-colorama_0.3.7-1_all.deb ...\n",
            "Unpacking python-colorama (0.3.7-1) ...\n",
            "Selecting previously unselected package python-click.\n",
            "Preparing to unpack .../07-python-click_6.7-3_all.deb ...\n",
            "Unpacking python-click (6.7-3) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../08-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../09-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../10-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../11-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../12-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python-itsdangerous.\n",
            "Preparing to unpack .../13-python-itsdangerous_0.24+dfsg1-2_all.deb ...\n",
            "Unpacking python-itsdangerous (0.24+dfsg1-2) ...\n",
            "Selecting previously unselected package python-markupsafe.\n",
            "Preparing to unpack .../14-python-markupsafe_1.0-1build1_amd64.deb ...\n",
            "Unpacking python-markupsafe (1.0-1build1) ...\n",
            "Selecting previously unselected package python-jinja2.\n",
            "Preparing to unpack .../15-python-jinja2_2.10-1ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package python-werkzeug.\n",
            "Preparing to unpack .../16-python-werkzeug_0.14.1+dfsg1-1ubuntu0.1_all.deb ...\n",
            "Unpacking python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-flask.\n",
            "Preparing to unpack .../17-python-flask_0.12.2-3ubuntu0.1_all.deb ...\n",
            "Unpacking python-flask (0.12.2-3ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../18-python3-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python3-openslide.\n",
            "Preparing to unpack .../19-python3-openslide_1.1.1-2ubuntu4_amd64.deb ...\n",
            "Unpacking python3-openslide (1.1.1-2ubuntu4) ...\n",
            "Selecting previously unselected package python-openslide-examples.\n",
            "Preparing to unpack .../20-python-openslide-examples_1.1.1-2ubuntu4_all.deb ...\n",
            "Unpacking python-openslide-examples (1.1.1-2ubuntu4) ...\n",
            "Selecting previously unselected package python-openssl.\n",
            "Preparing to unpack .../21-python-openssl_17.5.0-1ubuntu1_all.deb ...\n",
            "Unpacking python-openssl (17.5.0-1ubuntu1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../22-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-pyinotify.\n",
            "Preparing to unpack .../23-python-pyinotify_0.9.6-1_all.deb ...\n",
            "Unpacking python-pyinotify (0.9.6-1) ...\n",
            "Selecting previously unselected package python-simplejson.\n",
            "Preparing to unpack .../24-python-simplejson_3.13.2-1_amd64.deb ...\n",
            "Unpacking python-simplejson (3.13.2-1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../25-python3-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python3-olefile (0.45.1-1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-simplejson (3.13.2-1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python3-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-blinker (1.4+dfsg1-0.1) ...\n",
            "Setting up python3-olefile (0.45.1-1) ...\n",
            "Setting up python-colorama (0.3.7-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-markupsafe (1.0-1build1) ...\n",
            "Setting up python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n",
            "Setting up python-pyinotify (0.9.6-1) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up python-itsdangerous (0.24+dfsg1-2) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n",
            "Setting up python-click (6.7-3) ...\n",
            "Setting up python3-openslide (1.1.1-2ubuntu4) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python-flask (0.12.2-3ubuntu0.1) ...\n",
            "Setting up python-openssl (17.5.0-1ubuntu1) ...\n",
            "Setting up python-openslide-examples (1.1.1-2ubuntu4) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies and \n",
        "!pip install albumentations==0.4.6\n",
        "!pip install pycocotools --quiet\n",
        "\n",
        "# Clone TorchVision repo and copy helper files\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "%cd vision\n",
        "!git checkout v0.3.0\n",
        "%cd ..\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./\n",
        "\n",
        "\n",
        "# basic python and ML Libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# We will be reading images using OpenCV\n",
        "import cv2\n",
        "\n",
        "# matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# torchvision libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans  \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# helper libraries\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "# for image augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "!apt-get install python3-openslide\n",
        "from openslide import open_slide\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "folder = \"MyDrive/MIDOG_Challenge\"\n",
        "midog_folder = Path(\"/drive\") / Path(folder)\n",
        "print(list(midog_folder.glob(\"*.*\")))\n",
        "\n",
        "image_folder = Path(\"/content/drive/MyDrive/CSE499 Project/train_images\")\n",
        "\n",
        "hamamatsu_rx_ids = list(range(0, 51))\n",
        "hamamatsu_360_ids = list(range(51, 101))\n",
        "aperio_ids = list(range(101, 151))\n",
        "leica_ids = list(range(151, 201))\n",
        "\n",
        "\n",
        "annotation_file = midog_folder / \"MIDOG.json\"\n",
        "rows = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KVq-8YZGGjt",
        "outputId": "60d95f35-0820-4cf0-d744-25559631e4d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n",
            "[PosixPath('/drive/MyDrive/MIDOG_Challenge/MIDOG.sqlite'), PosixPath('/drive/MyDrive/MIDOG_Challenge/MIDOG.json')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(annotation_file) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "    categories = {1: 'mitotic figure', 2: 'hard negative'}\n",
        "\n",
        "    for row in data[\"images\"]:\n",
        "        file_name = row[\"file_name\"]\n",
        "        image_id = row[\"id\"]\n",
        "        width = row[\"width\"]\n",
        "        height = row[\"height\"]\n",
        "\n",
        "        scanner  = \"Hamamatsu XR\"\n",
        "        if image_id in hamamatsu_360_ids:\n",
        "            scanner  = \"Hamamatsu S360\"\n",
        "        if image_id in aperio_ids:\n",
        "            scanner  = \"Aperio CS\"\n",
        "        if image_id in leica_ids:\n",
        "            scanner  = \"Leica GT450\"\n",
        "         \n",
        "        for annotation in [anno for anno in data['annotations'] if anno[\"image_id\"] == image_id]:\n",
        "            box = annotation[\"bbox\"]\n",
        "            cat = categories[annotation[\"category_id\"]]\n",
        "\n",
        "            rows.append([file_name, image_id, width, height, box, cat, scanner])\n",
        "        \n",
        "df = pd.DataFrame(rows, columns=[\"file_name\", \"image_id\", \"width\", \"height\", \"box\", \"cat\", \"scanner\"])"
      ],
      "metadata": {
        "id": "KxbqTWLURrVA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cat']=='hard negative'].index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THjCrABr2Z77",
        "outputId": "31b20672-0e4b-4b20-bba7-703a7ca2d74e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   0,    1,    2,    3,    4,    7,   10,   11,   14,   15,\n",
              "            ...\n",
              "            4420, 4422, 4423, 4424, 4425, 4426, 4430, 4432, 4433, 4434],\n",
              "           dtype='int64', length=2714)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[df['cat']=='hard negative'].index,inplace=True)"
      ],
      "metadata": {
        "id": "PLhQKSb8XOtD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "VEsVe0ozYMhc",
        "outputId": "d591a4e6-abcd-4b66-b318-c1ca07113679"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4916c81d-f398-4088-a80a-c006f12f6e92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>image_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>box</th>\n",
              "      <th>cat</th>\n",
              "      <th>scanner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[4397, 191, 4447, 241]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[1842, 1558, 1892, 1608]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[5319, 3252, 5369, 3302]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[6242, 3193, 6292, 3243]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[4636, 4294, 4686, 4344]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4421</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[5373, 2398, 5423, 2448]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4427</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[3698, 3258, 3748, 3308]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[308, 4254, 358, 4304]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[553, 4394, 603, 4444]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[3730, 4538, 3780, 4588]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1721 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4916c81d-f398-4088-a80a-c006f12f6e92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4916c81d-f398-4088-a80a-c006f12f6e92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4916c81d-f398-4088-a80a-c006f12f6e92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     file_name  image_id  ...             cat       scanner\n",
              "5     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "6     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "8     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "9     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "12    002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "...        ...       ...  ...             ...           ...\n",
              "4421  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4427  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4428  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4429  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4431  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "\n",
              "[1721 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1 = df[df['scanner']=='Hamamatsu XR']\n",
        "dataset_2 = df[df['scanner']=='Hamamatsu S360']\n",
        "dataset_3 = df[df['scanner']=='Aperio CS']\n",
        "#dataset_4 = df[df['scanner']=='Leica GT450']"
      ],
      "metadata": {
        "id": "fPa3c1CrYTuq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_1['image_id'].unique())+len(dataset_2['image_id'].unique())+len(dataset_3['image_id'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbWOj6jFYiw6",
        "outputId": "6cdc5ca6-05be-47a3-80fd-3294241214b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = Path(\"/content/drive/MyDrive/CSE499 Project/train_images\")"
      ],
      "metadata": {
        "id": "x4ST5yE3dK_U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJDxlw5o12pL",
        "outputId": "7a4e4a11-27d1-4427-a0b4-9d1b249c87f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# img_id = 2\n",
        "# thumbail_size_big = 1024\n",
        "# slide = open_slide( str(image_folder / f\"{img_id:03d}.tiff\") )\n",
        "\n",
        "# image = slide.get_thumbnail((1443, 1082))\n",
        "\n",
        "# fig = px.imshow(image)\n",
        "\n",
        "# scale_x = slide.level_dimensions[0][0] / image.size[0]\n",
        "# scale_y = slide.level_dimensions[0][1] / image.size[1]\n",
        "\n",
        "# for id, anno in dataset_1[dataset_1[\"image_id\"] == img_id].iterrows():\n",
        "\n",
        "#     x0, y0, x1, y1 = anno.box[0] / scale_x, anno.box[1] / scale_y, anno.box[2] / scale_x, anno.box[3] / scale_y\n",
        "\n",
        "\n",
        "#     fig.add_shape(\n",
        "#         type='rect',\n",
        "#         x0=x0, x1=x1, y0=y0, y1=y1,\n",
        "#         xref='x', yref='y',\n",
        "#         line_color='red' if \"mitotic\" in anno[\"cat\"] else \"blue\"\n",
        "#     )\n",
        "\n",
        "# fig.update_layout(\n",
        "#     autosize=False,\n",
        "#     width=image.size[0],\n",
        "#     height=image.size[1],\n",
        "#     )\n",
        "\n",
        "# fig.show()    "
      ],
      "metadata": {
        "id": "A2B2IfB0SfwA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MitosisImagesDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, files_dir, width, height, dataset,transforms=None):\n",
        "    self.transforms = transforms\n",
        "    self.files_dir  = files_dir\n",
        "    self.height     = height\n",
        "    self.width      = width\n",
        "\n",
        "    self.imgs = [image for image in sorted(os.listdir(files_dir)) if image[-5:]=='.tiff' and image in dataset_1['file_name'].values]\n",
        "    \n",
        "    #self.classes = [_, 'mitotic figure']\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_name   = self.imgs[index]\n",
        "    image_path = os.path.join(self.files_dir, img_name)\n",
        "\n",
        "    img     = cv2.imread(image_path)\n",
        "    img     = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "    img     = cv2.resize(img, (self.width, self.height), cv2.INTER_AREA)\n",
        "\n",
        "    img    /= 255.0\n",
        "    \n",
        "    \n",
        "    dataframe = dataset_1[dataset_1['file_name']==img_name]\n",
        "    \n",
        "    boxes = []\n",
        "    labels = []\n",
        "\n",
        "    wt = img.shape[1]\n",
        "    ht = img.shape[0]\n",
        "    \n",
        "    for index in dataframe.index:\n",
        "      labels.append(1)\n",
        "      \n",
        "      List = dataframe['box'][index]\n",
        "      \n",
        "      scale_x = 7215/self.width\n",
        "      scale_y = 5412/self.height\n",
        "  \n",
        "      List[0]=List[0]/scale_x\n",
        "      List[2]=List[2]/scale_x\n",
        "      List[1]=List[1]/scale_y\n",
        "      List[3]=List[3]/scale_y\n",
        "\n",
        "      xmin = List[0]\n",
        "      xmax = List[2]\n",
        "      ymin = List[1]\n",
        "      ymax = List[3]\n",
        "        \n",
        "      xmin_corr = (xmin)\n",
        "      xmax_corr = (xmax)\n",
        "      ymin_corr = (ymin)\n",
        "      ymax_corr = (ymax)\n",
        "          \n",
        "      boxes.append([xmin_corr, ymin_corr, xmax_corr, ymax_corr])\n",
        "    \n",
        "\n",
        "\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "    #area = torch.as_tensor(area, dtype=torch.float32)\n",
        "    iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
        "    \n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"image_id\"] = torch.tensor([index])\n",
        "    target[\"area\"] = area\n",
        "    target[\"iscrowd\"] = iscrowd\n",
        "    \n",
        "    img = torchvision.transforms.ToTensor()(img)\n",
        "\n",
        "    return img, target\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.imgs)"
      ],
      "metadata": {
        "id": "V3Fo2gNUGb1S"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send train=True for training transforms and False for val/test transforms\n",
        "def get_transform(train):\n",
        "  if train:\n",
        "    return A.Compose(\n",
        "      [\n",
        "        A.HorizontalFlip(0.5),\n",
        "        # ToTensorV2 converts image to pytorch tensor without div by 255\n",
        "        ToTensorV2(p=1.0) \n",
        "      ],\n",
        "      bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}\n",
        "    )\n",
        "  else:\n",
        "    return A.Compose(\n",
        "      [ToTensorV2(p=1.0)],\n",
        "      bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}\n",
        "    )"
      ],
      "metadata": {
        "id": "CMBIlwdRShFx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_dir = '/content/drive/MyDrive/CSE499 Project/train_images'\n",
        "test_dir = '/content/drive/MyDrive/CSE499 Project/test_images'"
      ],
      "metadata": {
        "id": "KDuLWW4lOH9p"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset =      MitosisImagesDataset(files_dir, 480, 480,dataset_1,transforms=get_transform(train=False))\n",
        "dataset_test = MitosisImagesDataset(files_dir, 480, 480,dataset_1,transforms=get_transform(train=False))"
      ],
      "metadata": {
        "id": "XubkG2cR6Pkr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "eknoiscY6RTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faede2da-2894-4225-e2c7-17b4728f217c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.8043, 0.9302, 0.9069,  ..., 0.5588, 0.8601, 0.8914],\n",
              "          [0.7941, 0.8958, 0.9083,  ..., 0.9020, 0.7432, 0.9166],\n",
              "          [0.7131, 0.9394, 0.9578,  ..., 0.8909, 0.8853, 0.8485],\n",
              "          ...,\n",
              "          [0.8045, 0.9125, 0.9415,  ..., 0.8179, 0.7040, 0.8316],\n",
              "          [0.9068, 0.8735, 0.9395,  ..., 0.7585, 0.6956, 0.8213],\n",
              "          [0.8880, 0.8307, 0.9266,  ..., 0.8119, 0.8225, 0.8427]],\n",
              " \n",
              "         [[0.5674, 0.8692, 0.7097,  ..., 0.3130, 0.5027, 0.6179],\n",
              "          [0.5072, 0.8491, 0.8123,  ..., 0.5204, 0.4074, 0.7700],\n",
              "          [0.4834, 0.9149, 0.9158,  ..., 0.5005, 0.6711, 0.6287],\n",
              "          ...,\n",
              "          [0.6088, 0.7011, 0.8237,  ..., 0.5412, 0.4373, 0.6157],\n",
              "          [0.7490, 0.7370, 0.8159,  ..., 0.5175, 0.4052, 0.6148],\n",
              "          [0.7634, 0.6891, 0.8283,  ..., 0.5844, 0.5160, 0.5681]],\n",
              " \n",
              "         [[0.7720, 0.9122, 0.8528,  ..., 0.6492, 0.7754, 0.8516],\n",
              "          [0.7549, 0.8960, 0.9328,  ..., 0.8478, 0.6626, 0.8842],\n",
              "          [0.7643, 0.9312, 0.9435,  ..., 0.7789, 0.8619, 0.7947],\n",
              "          ...,\n",
              "          [0.7944, 0.9068, 0.9285,  ..., 0.8009, 0.7675, 0.8351],\n",
              "          [0.8498, 0.8593, 0.9363,  ..., 0.7771, 0.7412, 0.8236],\n",
              "          [0.9040, 0.8409, 0.8929,  ..., 0.8165, 0.8162, 0.8155]]]),\n",
              " {'area': tensor([14.7513, 14.7512, 14.7512, 14.7513, 14.7513, 14.7512, 14.7513, 14.7513,\n",
              "          14.7513]),\n",
              "  'boxes': tensor([[292.5239,  16.9401, 295.8503,  21.3747],\n",
              "          [122.5447, 138.1818, 125.8711, 142.6164],\n",
              "          [353.8628, 288.4257, 357.1892, 292.8603],\n",
              "          [415.2682, 283.1929, 418.5946, 287.6275],\n",
              "          [308.4241, 380.8426, 311.7505, 385.2772],\n",
              "          [ 86.8857, 435.6541,  90.2121, 440.0887],\n",
              "          [ 85.9210, 244.6120,  89.2474, 249.0466],\n",
              "          [233.2807, 218.3148, 236.6071, 222.7495],\n",
              "          [144.4990, 286.6962, 147.8254, 291.1308]]),\n",
              "  'image_id': tensor([19]),\n",
              "  'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =      MitosisImagesDataset(files_dir, 480, 480,dataset_1,transforms=get_transform(train=False))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_data_loader  = DataLoader(train_dataset,batch_size=10,shuffle=True,num_workers=4,collate_fn=utils.collate_fn)"
      ],
      "metadata": {
        "id": "XKrOjJhgxZdP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "-qPRofeYzrOa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBuRsJ3X0uTn",
        "outputId": "4c4cf66f-048e-45b4-f856-5b7684e27904"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt \n",
        "\n",
        "# images,targets = next(iter(train_data_loader))\n",
        "# images = list(image.to(device) for image in images)\n",
        "# targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "\n",
        "# boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
        "# img = images[0].permute(1,2,0).cpu().numpy()\n",
        "# fig,ax = plt.subplots(1, 1, figsize=(50,30))\n",
        "\n",
        "# for box in boxes:\n",
        "#   cv2.rectangle(img,\n",
        "#                 (box[0],box[1]),\n",
        "#                 (box[2],box[3]),\n",
        "#                 (220,0,0), 1)\n",
        "\n",
        "# ax.set_axis_off()\n",
        "# ax.imshow(img)"
      ],
      "metadata": {
        "id": "EAQerS6L9ND3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes=2\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) "
      ],
      "metadata": {
        "id": "tLhwVd903q9f"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "k3_Mn0GmAJEw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "_pU8uhDI3w4r"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itr = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for images,targets in train_data_loader:\n",
        "    images = list(image.to(device) for image in images)\n",
        "    targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "\n",
        "    loss_dict = model(images,targets)\n",
        "\n",
        "    losses = sum(loss for loss in loss_dict.values())\n",
        "    loss_value = losses.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if itr % 50 == 0:\n",
        "      print(f\"Iteration #{itr} loss: {loss_value}\")\n",
        "\n",
        "    itr+=1\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "  print(f\"Epoch #{epoch} loss: {loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVeM4q-K37xj",
        "outputId": "2a137e54-a986-4602-eea0-b821d18c59a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0 loss: 1.278481364250183\n",
            "Epoch #1 loss: 1.038503646850586\n",
            "Epoch #2 loss: 0.7167458534240723\n",
            "Epoch #3 loss: 1.0711729526519775\n",
            "Epoch #4 loss: 0.8949969410896301\n",
            "Epoch #5 loss: 0.8229814767837524\n",
            "Epoch #6 loss: 0.8153839707374573\n",
            "Epoch #7 loss: 0.9438090324401855\n",
            "Epoch #8 loss: 0.7520048022270203\n",
            "Iteration #50 loss: 1.083060622215271\n",
            "Epoch #9 loss: 1.083060622215271\n",
            "Epoch #10 loss: 0.8516127467155457\n",
            "Epoch #11 loss: 0.8825467824935913\n",
            "Epoch #12 loss: 1.0694729089736938\n",
            "Epoch #13 loss: 0.6851437091827393\n",
            "Epoch #14 loss: 1.135145664215088\n",
            "Epoch #15 loss: 0.8707451820373535\n",
            "Epoch #16 loss: 0.98777174949646\n",
            "Epoch #17 loss: 0.7367779016494751\n",
            "Epoch #18 loss: 0.7707308530807495\n",
            "Iteration #100 loss: 0.9232560396194458\n",
            "Epoch #19 loss: 0.9232560396194458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/CSE499 Project/modelSaves'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Bs3kaBKnM5",
        "outputId": "bb9b9518-166d-4409-f649-d3e31e28cd49"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1M-kTVs7g43FucvCjcPvKwiR8r1e1qtHe/CSE499 Project/modelSaves\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "torch.save({\n",
        "'epoch':epoch,\n",
        "'model_state_dict':model.state_dict(),\n",
        "'optimizer_state_dict':optimizer.state_dict(),\n",
        "},'ckpt.pth')"
      ],
      "metadata": {
        "id": "YnpIlXajP-OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # training for one epoch\n",
        "    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    #evaluate(model, data_loader_test, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPUUbUbj1lXS",
        "outputId": "722df567-8036-420a-c08a-c2d2d4ebd05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [0/5]  eta: 0:12:31  lr: 0.001254  loss: 8.2572 (8.2572)  loss_classifier: 0.3805 (0.3805)  loss_box_reg: 0.0200 (0.0200)  loss_objectness: 6.9114 (6.9114)  loss_rpn_box_reg: 0.9453 (0.9453)  time: 150.3408  data: 147.3893  max mem: 7153\n",
            "Epoch: [0]  [4/5]  eta: 0:00:32  lr: 0.005000  loss: 2.9613 (4.7788)  loss_classifier: 0.3372 (0.2733)  loss_box_reg: 0.0221 (0.0222)  loss_objectness: 1.9018 (3.5351)  loss_rpn_box_reg: 0.9453 (0.9481)  time: 32.9056  data: 31.4005  max mem: 7419\n",
            "Epoch: [0] Total time: 0:02:44 (32.9518 s / it)\n",
            "Epoch: [1]  [0/5]  eta: 0:04:03  lr: 0.005000  loss: 2.1186 (2.1186)  loss_classifier: 0.1205 (0.1205)  loss_box_reg: 0.0177 (0.0177)  loss_objectness: 0.4951 (0.4951)  loss_rpn_box_reg: 1.4852 (1.4852)  time: 48.7364  data: 47.3943  max mem: 7419\n",
            "Epoch: [1]  [4/5]  eta: 0:00:11  lr: 0.005000  loss: 3.3542 (4.8970)  loss_classifier: 0.2216 (0.4149)  loss_box_reg: 0.0177 (0.0429)  loss_objectness: 1.3374 (2.4685)  loss_rpn_box_reg: 1.6719 (1.9707)  time: 11.4079  data: 10.3518  max mem: 7419\n",
            "Epoch: [1] Total time: 0:00:57 (11.4605 s / it)\n",
            "Epoch: [2]  [0/5]  eta: 0:04:49  lr: 0.005000  loss: 2.4953 (2.4953)  loss_classifier: 0.2582 (0.2582)  loss_box_reg: 0.0230 (0.0230)  loss_objectness: 0.5355 (0.5355)  loss_rpn_box_reg: 1.6786 (1.6786)  time: 57.8647  data: 56.4702  max mem: 7419\n",
            "Epoch: [2]  [4/5]  eta: 0:00:12  lr: 0.005000  loss: 2.4953 (2.3184)  loss_classifier: 0.1010 (0.1355)  loss_box_reg: 0.0113 (0.0128)  loss_objectness: 0.5602 (0.7476)  loss_rpn_box_reg: 1.4774 (1.4226)  time: 12.9591  data: 11.8929  max mem: 7419\n",
            "Epoch: [2] Total time: 0:01:05 (13.0036 s / it)\n",
            "Epoch: [3]  [0/5]  eta: 0:04:32  lr: 0.000500  loss: 23.2888 (23.2888)  loss_classifier: 0.1117 (0.1117)  loss_box_reg: 0.0223 (0.0223)  loss_objectness: 11.2884 (11.2884)  loss_rpn_box_reg: 11.8664 (11.8664)  time: 54.5373  data: 53.3645  max mem: 7419\n",
            "Epoch: [3]  [4/5]  eta: 0:00:12  lr: 0.000500  loss: 1.5914 (5.9037)  loss_classifier: 0.1125 (0.1182)  loss_box_reg: 0.0099 (0.0132)  loss_objectness: 0.5717 (2.7066)  loss_rpn_box_reg: 0.8973 (3.0657)  time: 12.4093  data: 11.3938  max mem: 7419\n",
            "Epoch: [3] Total time: 0:01:02 (12.4622 s / it)\n",
            "Epoch: [4]  [0/5]  eta: 0:04:33  lr: 0.000500  loss: 1.5101 (1.5101)  loss_classifier: 0.0908 (0.0908)  loss_box_reg: 0.0083 (0.0083)  loss_objectness: 0.5226 (0.5226)  loss_rpn_box_reg: 0.8884 (0.8884)  time: 54.7803  data: 53.5674  max mem: 7419\n",
            "Epoch: [4]  [4/5]  eta: 0:00:12  lr: 0.000500  loss: 1.5101 (1.4814)  loss_classifier: 0.0908 (0.1124)  loss_box_reg: 0.0083 (0.0117)  loss_objectness: 0.5425 (0.5561)  loss_rpn_box_reg: 0.8409 (0.8013)  time: 12.4036  data: 11.3707  max mem: 7419\n",
            "Epoch: [4] Total time: 0:01:02 (12.4520 s / it)\n",
            "Epoch: [5]  [0/5]  eta: 0:04:11  lr: 0.000500  loss: 1.3490 (1.3490)  loss_classifier: 0.0951 (0.0951)  loss_box_reg: 0.0083 (0.0083)  loss_objectness: 0.6180 (0.6180)  loss_rpn_box_reg: 0.6276 (0.6276)  time: 50.3746  data: 48.8124  max mem: 7419\n",
            "Epoch: [5]  [4/5]  eta: 0:00:11  lr: 0.000500  loss: 0.9984 (1.1139)  loss_classifier: 0.0951 (0.0978)  loss_box_reg: 0.0082 (0.0070)  loss_objectness: 0.5298 (0.5436)  loss_rpn_box_reg: 0.3573 (0.4655)  time: 11.8531  data: 10.7517  max mem: 7419\n",
            "Epoch: [5] Total time: 0:00:59 (11.8992 s / it)\n",
            "Epoch: [6]  [0/5]  eta: 0:04:14  lr: 0.000050  loss: 0.9967 (0.9967)  loss_classifier: 0.0754 (0.0754)  loss_box_reg: 0.0031 (0.0031)  loss_objectness: 0.5504 (0.5504)  loss_rpn_box_reg: 0.3678 (0.3678)  time: 50.8222  data: 49.6709  max mem: 7419\n",
            "Epoch: [6]  [4/5]  eta: 0:00:11  lr: 0.000050  loss: 0.9654 (1.0098)  loss_classifier: 0.1037 (0.1060)  loss_box_reg: 0.0043 (0.0044)  loss_objectness: 0.5475 (0.5418)  loss_rpn_box_reg: 0.2994 (0.3576)  time: 11.8571  data: 10.8429  max mem: 7419\n",
            "Epoch: [6] Total time: 0:00:59 (11.9051 s / it)\n",
            "Epoch: [7]  [0/5]  eta: 0:04:32  lr: 0.000050  loss: 0.9297 (0.9297)  loss_classifier: 0.1469 (0.1469)  loss_box_reg: 0.0067 (0.0067)  loss_objectness: 0.5014 (0.5014)  loss_rpn_box_reg: 0.2748 (0.2748)  time: 54.5716  data: 53.3887  max mem: 7419\n",
            "Epoch: [7]  [4/5]  eta: 0:00:12  lr: 0.000050  loss: 0.8521 (0.8939)  loss_classifier: 0.0967 (0.1067)  loss_box_reg: 0.0028 (0.0036)  loss_objectness: 0.5014 (0.4978)  loss_rpn_box_reg: 0.2510 (0.2858)  time: 12.4227  data: 11.4054  max mem: 7419\n",
            "Epoch: [7] Total time: 0:01:02 (12.4745 s / it)\n",
            "Epoch: [8]  [0/5]  eta: 0:04:14  lr: 0.000050  loss: 0.8160 (0.8160)  loss_classifier: 0.1261 (0.1261)  loss_box_reg: 0.0035 (0.0035)  loss_objectness: 0.4911 (0.4911)  loss_rpn_box_reg: 0.1952 (0.1952)  time: 50.9413  data: 49.7666  max mem: 7419\n",
            "Epoch: [8]  [4/5]  eta: 0:00:12  lr: 0.000050  loss: 0.7961 (0.8265)  loss_classifier: 0.1121 (0.0999)  loss_box_reg: 0.0022 (0.0024)  loss_objectness: 0.4917 (0.4938)  loss_rpn_box_reg: 0.1798 (0.2304)  time: 12.1427  data: 11.1205  max mem: 7419\n",
            "Epoch: [8] Total time: 0:01:00 (12.1985 s / it)\n",
            "Epoch: [9]  [0/5]  eta: 0:04:34  lr: 0.000005  loss: 0.7713 (0.7713)  loss_classifier: 0.0989 (0.0989)  loss_box_reg: 0.0032 (0.0032)  loss_objectness: 0.4959 (0.4959)  loss_rpn_box_reg: 0.1733 (0.1733)  time: 54.9045  data: 53.6717  max mem: 7419\n",
            "Epoch: [9]  [4/5]  eta: 0:00:12  lr: 0.000005  loss: 0.7713 (0.9144)  loss_classifier: 0.0989 (0.1101)  loss_box_reg: 0.0032 (0.0030)  loss_objectness: 0.4959 (0.4940)  loss_rpn_box_reg: 0.1733 (0.3072)  time: 12.7105  data: 11.6862  max mem: 7419\n",
            "Epoch: [9] Total time: 0:01:03 (12.7664 s / it)\n",
            "Epoch: [10]  [0/5]  eta: 0:04:21  lr: 0.000005  loss: 0.7492 (0.7492)  loss_classifier: 0.0925 (0.0925)  loss_box_reg: 0.0015 (0.0015)  loss_objectness: 0.4863 (0.4863)  loss_rpn_box_reg: 0.1689 (0.1689)  time: 52.2148  data: 50.8393  max mem: 7419\n",
            "Epoch: [10]  [4/5]  eta: 0:00:11  lr: 0.000005  loss: 0.7846 (0.8249)  loss_classifier: 0.1154 (0.1064)  loss_box_reg: 0.0031 (0.0028)  loss_objectness: 0.4940 (0.4952)  loss_rpn_box_reg: 0.1689 (0.2205)  time: 11.6307  data: 10.5747  max mem: 7419\n",
            "Epoch: [10] Total time: 0:00:58 (11.6871 s / it)\n",
            "Epoch: [11]  [0/5]  eta: 0:04:14  lr: 0.000005  loss: 0.8157 (0.8157)  loss_classifier: 0.1588 (0.1588)  loss_box_reg: 0.0058 (0.0058)  loss_objectness: 0.4828 (0.4828)  loss_rpn_box_reg: 0.1682 (0.1682)  time: 50.8382  data: 49.5864  max mem: 7419\n",
            "Epoch: [11]  [4/5]  eta: 0:00:12  lr: 0.000005  loss: 0.7746 (0.8200)  loss_classifier: 0.0891 (0.1026)  loss_box_reg: 0.0019 (0.0025)  loss_objectness: 0.4983 (0.4935)  loss_rpn_box_reg: 0.1675 (0.2213)  time: 12.0034  data: 10.9730  max mem: 7419\n",
            "Epoch: [11] Total time: 0:01:00 (12.0547 s / it)\n",
            "Epoch: [12]  [0/5]  eta: 0:04:33  lr: 0.000001  loss: 0.8169 (0.8169)  loss_classifier: 0.1630 (0.1630)  loss_box_reg: 0.0043 (0.0043)  loss_objectness: 0.4819 (0.4819)  loss_rpn_box_reg: 0.1676 (0.1676)  time: 54.6698  data: 53.4585  max mem: 7419\n",
            "Epoch: [12]  [4/5]  eta: 0:00:12  lr: 0.000001  loss: 0.7735 (0.8205)  loss_classifier: 0.0904 (0.1027)  loss_box_reg: 0.0031 (0.0028)  loss_objectness: 0.4928 (0.4940)  loss_rpn_box_reg: 0.1717 (0.2210)  time: 12.1544  data: 11.1301  max mem: 7419\n",
            "Epoch: [12] Total time: 0:01:01 (12.2101 s / it)\n",
            "Epoch: [13]  [0/5]  eta: 0:04:34  lr: 0.000001  loss: 1.0569 (1.0569)  loss_classifier: 0.1171 (0.1171)  loss_box_reg: 0.0031 (0.0031)  loss_objectness: 0.4959 (0.4959)  loss_rpn_box_reg: 0.4408 (0.4408)  time: 54.9778  data: 53.7803  max mem: 7419\n",
            "Epoch: [13]  [4/5]  eta: 0:00:12  lr: 0.000001  loss: 0.7624 (0.8108)  loss_classifier: 0.1126 (0.1001)  loss_box_reg: 0.0029 (0.0027)  loss_objectness: 0.4855 (0.4858)  loss_rpn_box_reg: 0.1712 (0.2222)  time: 12.1468  data: 11.1273  max mem: 7419\n",
            "Epoch: [13] Total time: 0:01:00 (12.1993 s / it)\n",
            "Epoch: [14]  [0/5]  eta: 0:04:45  lr: 0.000001  loss: 0.7440 (0.7440)  loss_classifier: 0.0805 (0.0805)  loss_box_reg: 0.0015 (0.0015)  loss_objectness: 0.4925 (0.4925)  loss_rpn_box_reg: 0.1695 (0.1695)  time: 57.1537  data: 55.9461  max mem: 7419\n",
            "Epoch: [14]  [4/5]  eta: 0:00:12  lr: 0.000001  loss: 0.7803 (0.8201)  loss_classifier: 0.1161 (0.1064)  loss_box_reg: 0.0030 (0.0025)  loss_objectness: 0.4924 (0.4903)  loss_rpn_box_reg: 0.1695 (0.2209)  time: 12.6254  data: 11.6026  max mem: 7419\n",
            "Epoch: [14] Total time: 0:01:03 (12.6826 s / it)\n",
            "Epoch: [15]  [0/5]  eta: 0:04:42  lr: 0.000000  loss: 0.8179 (0.8179)  loss_classifier: 0.1623 (0.1623)  loss_box_reg: 0.0051 (0.0051)  loss_objectness: 0.4854 (0.4854)  loss_rpn_box_reg: 0.1651 (0.1651)  time: 56.4247  data: 55.0794  max mem: 7419\n",
            "Epoch: [15]  [4/5]  eta: 0:00:13  lr: 0.000000  loss: 0.7587 (0.8064)  loss_classifier: 0.0821 (0.1007)  loss_box_reg: 0.0023 (0.0024)  loss_objectness: 0.4854 (0.4862)  loss_rpn_box_reg: 0.1635 (0.2171)  time: 13.1028  data: 12.0269  max mem: 7419\n",
            "Epoch: [15] Total time: 0:01:05 (13.1607 s / it)\n",
            "Epoch: [16]  [0/5]  eta: 0:04:15  lr: 0.000000  loss: 1.0333 (1.0333)  loss_classifier: 0.0980 (0.0980)  loss_box_reg: 0.0021 (0.0021)  loss_objectness: 0.4968 (0.4968)  loss_rpn_box_reg: 0.4364 (0.4364)  time: 51.1736  data: 49.9820  max mem: 7419\n",
            "Epoch: [16]  [4/5]  eta: 0:00:12  lr: 0.000000  loss: 0.7533 (0.8058)  loss_classifier: 0.0980 (0.1023)  loss_box_reg: 0.0024 (0.0024)  loss_objectness: 0.4784 (0.4823)  loss_rpn_box_reg: 0.1650 (0.2189)  time: 12.1765  data: 11.1491  max mem: 7419\n",
            "Epoch: [16] Total time: 0:01:01 (12.2339 s / it)\n",
            "Epoch: [17]  [0/5]  eta: 0:04:38  lr: 0.000000  loss: 0.7316 (0.7316)  loss_classifier: 0.0715 (0.0715)  loss_box_reg: 0.0009 (0.0009)  loss_objectness: 0.4984 (0.4984)  loss_rpn_box_reg: 0.1609 (0.1609)  time: 55.6897  data: 54.5193  max mem: 7419\n",
            "Epoch: [17]  [4/5]  eta: 0:00:12  lr: 0.000000  loss: 0.7689 (0.8131)  loss_classifier: 0.1153 (0.0999)  loss_box_reg: 0.0024 (0.0024)  loss_objectness: 0.4870 (0.4908)  loss_rpn_box_reg: 0.1639 (0.2200)  time: 12.3244  data: 11.3075  max mem: 7419\n",
            "Epoch: [17] Total time: 0:01:01 (12.3805 s / it)\n",
            "Epoch: [18]  [0/5]  eta: 0:04:57  lr: 0.000000  loss: 0.7870 (0.7870)  loss_classifier: 0.1251 (0.1251)  loss_box_reg: 0.0031 (0.0031)  loss_objectness: 0.4992 (0.4992)  loss_rpn_box_reg: 0.1596 (0.1596)  time: 59.4363  data: 58.2703  max mem: 7419\n",
            "Epoch: [18]  [4/5]  eta: 0:00:12  lr: 0.000000  loss: 0.7674 (0.8090)  loss_classifier: 0.1113 (0.0969)  loss_box_reg: 0.0029 (0.0023)  loss_objectness: 0.4923 (0.4898)  loss_rpn_box_reg: 0.1683 (0.2200)  time: 12.8438  data: 11.8210  max mem: 7419\n",
            "Epoch: [18] Total time: 0:01:04 (12.9032 s / it)\n",
            "Epoch: [19]  [0/5]  eta: 0:04:00  lr: 0.000000  loss: 0.7886 (0.7886)  loss_classifier: 0.1246 (0.1246)  loss_box_reg: 0.0026 (0.0026)  loss_objectness: 0.4940 (0.4940)  loss_rpn_box_reg: 0.1673 (0.1673)  time: 48.1559  data: 46.9897  max mem: 7419\n",
            "Epoch: [19]  [4/5]  eta: 0:00:11  lr: 0.000000  loss: 0.7732 (0.8071)  loss_classifier: 0.1027 (0.0962)  loss_box_reg: 0.0026 (0.0023)  loss_objectness: 0.4919 (0.4904)  loss_rpn_box_reg: 0.1673 (0.2182)  time: 11.5873  data: 10.5726  max mem: 7419\n",
            "Epoch: [19] Total time: 0:00:58 (11.6415 s / it)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./model.pth'))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "_ng_I6SMF3w9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset =      MitosisImagesDataset(files_dir, 480, 480,dataset_1,transforms=get_transform(train=False))\n",
        "\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "\n",
        "test_split = 0.2\n",
        "tsize = int(len(test_dataset)*test_split)\n",
        "\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, indices[-tsize:])\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "  test_dataset,\n",
        "  batch_size=10,\n",
        "  shuffle=False,\n",
        "  num_workers=4,\n",
        "  collate_fn=utils.collate_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "rUq5rCuJXfq8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coco_utils import get_coco_api_from_dataset\n",
        "from coco_eval import CocoEvaluator\n",
        "import time\n",
        "\n",
        "def _get_iou_types(model):\n",
        "    model_without_ddp = model\n",
        "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
        "        model_without_ddp = model.module\n",
        "    iou_types = [\"bbox\"]\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
        "        iou_types.append(\"segm\")\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
        "        iou_types.append(\"keypoints\")\n",
        "    return iou_types\n"
      ],
      "metadata": {
        "id": "Pe5NhN9vqvZy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    n_threads = torch.get_num_threads()\n",
        "    # FIXME remove this and make paste_masks_in_image run on the GPU\n",
        "    torch.set_num_threads(1)\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    model.eval()\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = \"Test:\"\n",
        "\n",
        "    coco = get_coco_api_from_dataset(data_loader.dataset)\n",
        "    iou_types = _get_iou_types(model)\n",
        "    coco_evaluator = CocoEvaluator(coco, iou_types)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
        "        images = list(img.to(device) for img in images)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        model_time = time.time()\n",
        "        outputs = model(images)\n",
        "\n",
        "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
        "        model_time = time.time() - model_time\n",
        "\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        evaluator_time = time.time()\n",
        "        coco_evaluator.update(res)\n",
        "        evaluator_time = time.time() - evaluator_time\n",
        "        metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    coco_evaluator.synchronize_between_processes()\n",
        "\n",
        "    # accumulate predictions from all images\n",
        "    coco_evaluator.accumulate()\n",
        "    coco_evaluator.summarize()\n",
        "    torch.set_num_threads(n_threads)\n",
        "    return coco_evaluator"
      ],
      "metadata": {
        "id": "ub0hvADTpsaf"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model,test_data_loader,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilr9aW6Cq76v",
        "outputId": "b248e5ac-2b63-4c3b-ead1-cf9f732739bc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [0/1]  eta: 0:00:05  model_time: 0.4503 (0.4503)  evaluator_time: 0.0102 (0.0102)  time: 5.4460  data: 4.9768  max mem: 4198\n",
            "Test: Total time: 0:00:05 (5.5839 s / it)\n",
            "Averaged stats: model_time: 0.4503 (0.4503)  evaluator_time: 0.0102 (0.0102)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coco_eval.CocoEvaluator at 0x7f8f9eab6310>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_get_iou_types(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf2J5yI_rAqv",
        "outputId": "42ccd494-352e-4255-e286-180a8df809ea"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bbox']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric_logger = utils.MetricLogger(delimiter=\"  \")"
      ],
      "metadata": {
        "id": "QXkAfuJbsccM"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "HaRfPP_Hu8Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,targets in metric_logger.log_every(test_data_loader, 20, \"Test:\"):\n",
        "  images = list(img.to(device) for img in images)\n",
        "  outputs = model(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhkDUBXqr7Hp",
        "outputId": "910c61e2-ff78-4f6f-ac62-d1bbf4884557"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [0/1]  eta: 0:00:05    time: 5.3430  data: 4.9099  max mem: 14010\n",
            "Test: Total time: 0:00:05 (5.4625 s / it)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5GMsYEKseeY",
        "outputId": "3d52d35c-d54c-4ac9-da66-e4be0eb347e3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7351, 0.9058, 0.7882,  ..., 0.8693, 0.4645, 0.4778],\n",
              "         [0.8875, 0.8364, 0.9017,  ..., 0.7611, 0.8373, 0.3781],\n",
              "         [0.8055, 0.8575, 0.5814,  ..., 0.7822, 0.8080, 0.6478],\n",
              "         ...,\n",
              "         [0.3841, 0.5094, 0.5809,  ..., 0.8873, 0.8497, 0.8162],\n",
              "         [0.6801, 0.6142, 0.5937,  ..., 0.9629, 0.5700, 0.8521],\n",
              "         [0.5729, 0.5166, 0.8065,  ..., 0.9381, 0.9365, 0.9307]],\n",
              "\n",
              "        [[0.3364, 0.6407, 0.4384,  ..., 0.6001, 0.2082, 0.2010],\n",
              "         [0.4327, 0.4909, 0.5490,  ..., 0.4419, 0.5520, 0.1527],\n",
              "         [0.3593, 0.4020, 0.3353,  ..., 0.4237, 0.4602, 0.3460],\n",
              "         ...,\n",
              "         [0.2141, 0.3200, 0.3401,  ..., 0.7820, 0.3727, 0.3667],\n",
              "         [0.4003, 0.3675, 0.3585,  ..., 0.8812, 0.2844, 0.4824],\n",
              "         [0.3488, 0.3206, 0.4810,  ..., 0.7214, 0.7704, 0.7469]],\n",
              "\n",
              "        [[0.7784, 0.7737, 0.8183,  ..., 0.8204, 0.5750, 0.5854],\n",
              "         [0.6888, 0.7016, 0.7914,  ..., 0.7611, 0.7707, 0.4502],\n",
              "         [0.7361, 0.7501, 0.6398,  ..., 0.7438, 0.7694, 0.7007],\n",
              "         ...,\n",
              "         [0.5749, 0.6241, 0.6622,  ..., 0.8684, 0.7402, 0.8611],\n",
              "         [0.7084, 0.6648, 0.6292,  ..., 0.9810, 0.6085, 0.8324],\n",
              "         [0.7975, 0.7144, 0.7648,  ..., 0.8934, 0.8845, 0.9100]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh1T9QZ4s9ah",
        "outputId": "853eed73-e40c-4c31-a203-ee639349d023"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
              " 'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
              " 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JTehr_YRyuNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}