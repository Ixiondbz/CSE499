{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Z-dzLnxqiJK6B5de5osWnELx-H5Ftq0c",
      "authorship_tag": "ABX9TyOnAQTWYiWRjJ2+YjmkNs5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ixiondbz/CSE499/blob/main/NEW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UqOA1MxA8npn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3800b7-b905-4cda-bf78-7142f70d2a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=71aceaa9fd6d25691d4e6062d1e0aae77575ac6d2f425042b2ecfab54ee33056\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n",
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 73159, done.\u001b[K\n",
            "remote: Counting objects: 100% (8221/8221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (669/669), done.\u001b[K\n",
            "remote: Total 73159 (delta 7583), reused 8075 (delta 7509), pack-reused 64938\u001b[K\n",
            "Receiving objects: 100% (73159/73159), 142.86 MiB | 31.94 MiB/s, done.\n",
            "Resolving deltas: 100% (60710/60710), done.\n",
            "/content/vision\n",
            "Note: checking out 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at be376084d version check against PyTorch's CUDA version\n",
            "/content\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libjs-jquery libopenslide0 python-asn1crypto\n",
            "  python-blinker python-cffi-backend python-click python-colorama\n",
            "  python-cryptography python-enum34 python-flask python-idna python-ipaddress\n",
            "  python-itsdangerous python-jinja2 python-markupsafe\n",
            "  python-openslide-examples python-openssl python-pkg-resources\n",
            "  python-pyinotify python-simplejson python-six python-werkzeug\n",
            "  python3-olefile python3-pil\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd python-blinker-doc python-cryptography-doc\n",
            "  python-cryptography-vectors python-enum34-doc python-flask-doc\n",
            "  python-jinja2-doc python-openssl-doc python-openssl-dbg python-setuptools\n",
            "  python-pyinotify-doc ipython python-genshi python-lxml python-greenlet\n",
            "  python-redis python-pylibmc | python-memcache python-termcolor\n",
            "  python-watchdog python-werkzeug-doc python-pil-doc python3-pil-dbg\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libjs-jquery libopenslide0 python-asn1crypto\n",
            "  python-blinker python-cffi-backend python-click python-colorama\n",
            "  python-cryptography python-enum34 python-flask python-idna python-ipaddress\n",
            "  python-itsdangerous python-jinja2 python-markupsafe\n",
            "  python-openslide-examples python-openssl python-pkg-resources\n",
            "  python-pyinotify python-simplejson python-six python-werkzeug\n",
            "  python3-olefile python3-openslide python3-pil\n",
            "0 upgraded, 26 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,997 kB of archives.\n",
            "After this operation, 9,740 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-blinker all 1.4+dfsg1-0.1 [13.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-colorama all 0.3.7-1 [22.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-click all 6.7-3 [56.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-itsdangerous all 0.24+dfsg1-2 [11.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-markupsafe amd64 1.0-1build1 [13.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-jinja2 all 2.10-1ubuntu0.18.04.1 [94.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-werkzeug all 0.14.1+dfsg1-1ubuntu0.1 [174 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-flask all 0.12.2-3ubuntu0.1 [62.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.6 [330 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-openslide amd64 1.1.1-2ubuntu4 [16.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-openslide-examples all 1.1.1-2ubuntu4 [168 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-openssl all 17.5.0-1ubuntu1 [41.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pyinotify all 0.9.6-1 [24.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-simplejson amd64 3.13.2-1 [61.2 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n",
            "Fetched 1,997 kB in 2s (1,281 kB/s)\n",
            "Selecting previously unselected package javascript-common.\n",
            "(Reading database ... 155225 files and directories currently installed.)\n",
            "Preparing to unpack .../00-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../01-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libopenslide0.\n",
            "Preparing to unpack .../02-libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-blinker.\n",
            "Preparing to unpack .../04-python-blinker_1.4+dfsg1-0.1_all.deb ...\n",
            "Unpacking python-blinker (1.4+dfsg1-0.1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../05-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-colorama.\n",
            "Preparing to unpack .../06-python-colorama_0.3.7-1_all.deb ...\n",
            "Unpacking python-colorama (0.3.7-1) ...\n",
            "Selecting previously unselected package python-click.\n",
            "Preparing to unpack .../07-python-click_6.7-3_all.deb ...\n",
            "Unpacking python-click (6.7-3) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../08-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../09-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../10-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../11-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../12-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python-itsdangerous.\n",
            "Preparing to unpack .../13-python-itsdangerous_0.24+dfsg1-2_all.deb ...\n",
            "Unpacking python-itsdangerous (0.24+dfsg1-2) ...\n",
            "Selecting previously unselected package python-markupsafe.\n",
            "Preparing to unpack .../14-python-markupsafe_1.0-1build1_amd64.deb ...\n",
            "Unpacking python-markupsafe (1.0-1build1) ...\n",
            "Selecting previously unselected package python-jinja2.\n",
            "Preparing to unpack .../15-python-jinja2_2.10-1ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package python-werkzeug.\n",
            "Preparing to unpack .../16-python-werkzeug_0.14.1+dfsg1-1ubuntu0.1_all.deb ...\n",
            "Unpacking python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-flask.\n",
            "Preparing to unpack .../17-python-flask_0.12.2-3ubuntu0.1_all.deb ...\n",
            "Unpacking python-flask (0.12.2-3ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../18-python3-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python3-openslide.\n",
            "Preparing to unpack .../19-python3-openslide_1.1.1-2ubuntu4_amd64.deb ...\n",
            "Unpacking python3-openslide (1.1.1-2ubuntu4) ...\n",
            "Selecting previously unselected package python-openslide-examples.\n",
            "Preparing to unpack .../20-python-openslide-examples_1.1.1-2ubuntu4_all.deb ...\n",
            "Unpacking python-openslide-examples (1.1.1-2ubuntu4) ...\n",
            "Selecting previously unselected package python-openssl.\n",
            "Preparing to unpack .../21-python-openssl_17.5.0-1ubuntu1_all.deb ...\n",
            "Unpacking python-openssl (17.5.0-1ubuntu1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../22-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-pyinotify.\n",
            "Preparing to unpack .../23-python-pyinotify_0.9.6-1_all.deb ...\n",
            "Unpacking python-pyinotify (0.9.6-1) ...\n",
            "Selecting previously unselected package python-simplejson.\n",
            "Preparing to unpack .../24-python-simplejson_3.13.2-1_amd64.deb ...\n",
            "Unpacking python-simplejson (3.13.2-1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../25-python3-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python3-olefile (0.45.1-1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-simplejson (3.13.2-1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python3-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-blinker (1.4+dfsg1-0.1) ...\n",
            "Setting up python3-olefile (0.45.1-1) ...\n",
            "Setting up python-colorama (0.3.7-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-markupsafe (1.0-1build1) ...\n",
            "Setting up python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n",
            "Setting up python-pyinotify (0.9.6-1) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up python-itsdangerous (0.24+dfsg1-2) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n",
            "Setting up python-click (6.7-3) ...\n",
            "Setting up python3-openslide (1.1.1-2ubuntu4) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python-flask (0.12.2-3ubuntu0.1) ...\n",
            "Setting up python-openssl (17.5.0-1ubuntu1) ...\n",
            "Setting up python-openslide-examples (1.1.1-2ubuntu4) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies and \n",
        "!pip install albumentations==0.4.6\n",
        "!pip install pycocotools --quiet\n",
        "\n",
        "# Clone TorchVision repo and copy helper files\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "%cd vision\n",
        "!git checkout v0.3.0\n",
        "%cd ..\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./\n",
        "\n",
        "\n",
        "# basic python and ML Libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# We will be reading images using OpenCV\n",
        "import cv2\n",
        "\n",
        "# matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# torchvision libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans  \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# helper libraries\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "# for image augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "!apt-get install python3-openslide\n",
        "from openslide import open_slide\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "folder = \"MyDrive/MIDOG_Challenge\"\n",
        "midog_folder = Path(\"/drive\") / Path(folder)\n",
        "print(list(midog_folder.glob(\"*.*\")))\n",
        "\n",
        "image_folder = Path(\"/content/drive/MyDrive/CSE499 Project/train_images\")\n",
        "\n",
        "hamamatsu_rx_ids = list(range(0, 51))\n",
        "hamamatsu_360_ids = list(range(51, 101))\n",
        "aperio_ids = list(range(101, 151))\n",
        "leica_ids = list(range(151, 201))\n",
        "\n",
        "\n",
        "annotation_file = midog_folder / \"MIDOG.json\"\n",
        "rows = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KVq-8YZGGjt",
        "outputId": "c55f2a16-3378-47ad-875a-7c991ba8980d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n",
            "[PosixPath('/drive/MyDrive/MIDOG_Challenge/MIDOG.sqlite'), PosixPath('/drive/MyDrive/MIDOG_Challenge/MIDOG.json')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(annotation_file) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "    categories = {1: 'mitotic figure', 2: 'hard negative'}\n",
        "\n",
        "    for row in data[\"images\"]:\n",
        "        file_name = row[\"file_name\"]\n",
        "        image_id = row[\"id\"]\n",
        "        width = row[\"width\"]\n",
        "        height = row[\"height\"]\n",
        "\n",
        "        scanner  = \"Hamamatsu XR\"\n",
        "        if image_id in hamamatsu_360_ids:\n",
        "            scanner  = \"Hamamatsu S360\"\n",
        "        if image_id in aperio_ids:\n",
        "            scanner  = \"Aperio CS\"\n",
        "        if image_id in leica_ids:\n",
        "            scanner  = \"Leica GT450\"\n",
        "         \n",
        "        for annotation in [anno for anno in data['annotations'] if anno[\"image_id\"] == image_id]:\n",
        "            box = annotation[\"bbox\"]\n",
        "            cat = categories[annotation[\"category_id\"]]\n",
        "\n",
        "            rows.append([file_name, image_id, width, height, box, cat, scanner])\n",
        "        \n",
        "df = pd.DataFrame(rows, columns=[\"file_name\", \"image_id\", \"width\", \"height\", \"box\", \"cat\", \"scanner\"])"
      ],
      "metadata": {
        "id": "KxbqTWLURrVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cat']=='hard negative'].index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THjCrABr2Z77",
        "outputId": "31b20672-0e4b-4b20-bba7-703a7ca2d74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   0,    1,    2,    3,    4,    7,   10,   11,   14,   15,\n",
              "            ...\n",
              "            4420, 4422, 4423, 4424, 4425, 4426, 4430, 4432, 4433, 4434],\n",
              "           dtype='int64', length=2714)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[df['cat']=='hard negative'].index,inplace=True)"
      ],
      "metadata": {
        "id": "PLhQKSb8XOtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "VEsVe0ozYMhc",
        "outputId": "d591a4e6-abcd-4b66-b318-c1ca07113679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4916c81d-f398-4088-a80a-c006f12f6e92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>image_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>box</th>\n",
              "      <th>cat</th>\n",
              "      <th>scanner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[4397, 191, 4447, 241]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[1842, 1558, 1892, 1608]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[5319, 3252, 5369, 3302]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[6242, 3193, 6292, 3243]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[4636, 4294, 4686, 4344]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4421</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[5373, 2398, 5423, 2448]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4427</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[3698, 3258, 3748, 3308]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[308, 4254, 358, 4304]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[553, 4394, 603, 4444]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>150.tiff</td>\n",
              "      <td>150</td>\n",
              "      <td>6467</td>\n",
              "      <td>4862</td>\n",
              "      <td>[3730, 4538, 3780, 4588]</td>\n",
              "      <td>mitotic figure</td>\n",
              "      <td>Aperio CS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1721 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4916c81d-f398-4088-a80a-c006f12f6e92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4916c81d-f398-4088-a80a-c006f12f6e92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4916c81d-f398-4088-a80a-c006f12f6e92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     file_name  image_id  ...             cat       scanner\n",
              "5     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "6     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "8     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "9     002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "12    002.tiff         2  ...  mitotic figure  Hamamatsu XR\n",
              "...        ...       ...  ...             ...           ...\n",
              "4421  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4427  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4428  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4429  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "4431  150.tiff       150  ...  mitotic figure     Aperio CS\n",
              "\n",
              "[1721 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1 = df[df['scanner']=='Hamamatsu XR']\n",
        "dataset_2 = df[df['scanner']=='Hamamatsu S360']\n",
        "dataset_3 = df[df['scanner']=='Aperio CS']\n",
        "#dataset_4 = df[df['scanner']=='Leica GT450']"
      ],
      "metadata": {
        "id": "fPa3c1CrYTuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_1['image_id'].unique())+len(dataset_2['image_id'].unique())+len(dataset_3['image_id'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbWOj6jFYiw6",
        "outputId": "6cdc5ca6-05be-47a3-80fd-3294241214b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = Path(\"/content/drive/MyDrive/CSE499 Project/train_images\")"
      ],
      "metadata": {
        "id": "x4ST5yE3dK_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJDxlw5o12pL",
        "outputId": "7a4e4a11-27d1-4427-a0b4-9d1b249c87f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# img_id = 2\n",
        "# thumbail_size_big = 1024\n",
        "# slide = open_slide( str(image_folder / f\"{img_id:03d}.tiff\") )\n",
        "\n",
        "# image = slide.get_thumbnail((1443, 1082))\n",
        "\n",
        "# fig = px.imshow(image)\n",
        "\n",
        "# scale_x = slide.level_dimensions[0][0] / image.size[0]\n",
        "# scale_y = slide.level_dimensions[0][1] / image.size[1]\n",
        "\n",
        "# for id, anno in dataset_1[dataset_1[\"image_id\"] == img_id].iterrows():\n",
        "\n",
        "#     x0, y0, x1, y1 = anno.box[0] / scale_x, anno.box[1] / scale_y, anno.box[2] / scale_x, anno.box[3] / scale_y\n",
        "\n",
        "\n",
        "#     fig.add_shape(\n",
        "#         type='rect',\n",
        "#         x0=x0, x1=x1, y0=y0, y1=y1,\n",
        "#         xref='x', yref='y',\n",
        "#         line_color='red' if \"mitotic\" in anno[\"cat\"] else \"blue\"\n",
        "#     )\n",
        "\n",
        "# fig.update_layout(\n",
        "#     autosize=False,\n",
        "#     width=image.size[0],\n",
        "#     height=image.size[1],\n",
        "#     )\n",
        "\n",
        "# fig.show()    "
      ],
      "metadata": {
        "id": "A2B2IfB0SfwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame = pd.read_pickle('/drive/MyDrive/CSE499 Project/Patch Datasets/Hamamatsu XR/DataFrame.pkl')"
      ],
      "metadata": {
        "id": "X6NNUGYFkzUq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(541):\n",
        "  xmin,ymin,xmax,ymax = DataFrame.box[i]\n",
        "  if xmin>xmax or ymin>ymax:\n",
        "    print(i)\n",
        "    break"
      ],
      "metadata": {
        "id": "DEfyx0e_lqCg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MitosisImagesDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, files_dir, width, height,transforms=None):\n",
        "    self.transforms = transforms\n",
        "    self.files_dir  = files_dir\n",
        "    self.height     = height\n",
        "    self.width      = width\n",
        "\n",
        "    self.imgs = [image for image in sorted(os.listdir(files_dir)) if image[-5:]=='.tiff']\n",
        "    \n",
        "    self.classes = [_, 'mitotic figure']\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name   = self.imgs[idx]\n",
        "    image_path = os.path.join(self.files_dir, img_name)\n",
        "\n",
        "    img     = cv2.imread(image_path)\n",
        "    img     = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "    img     = cv2.resize(img, (self.width, self.height), cv2.INTER_AREA)\n",
        "\n",
        "    img    /= 255.0\n",
        "    \n",
        "    \n",
        "    dataframe = DataFrame[DataFrame['file_name']==img_name].copy()\n",
        "    \n",
        "    boxes = []\n",
        "    labels = []\n",
        "\n",
        "    wt = img.shape[1]\n",
        "    ht = img.shape[0]\n",
        "    \n",
        "    for index in dataframe.index:\n",
        "      labels.append(1)\n",
        "      \n",
        "      List = dataframe['box'][index]\n",
        "      \n",
        "      scale_x = 7215/self.width\n",
        "      scale_y = 5412/self.height\n",
        "\n",
        "      xmin = List[0]/scale_x\n",
        "      xmax = List[2]/scale_x\n",
        "      ymin = List[1]/scale_y\n",
        "      ymax = List[3]/scale_y\n",
        "        \n",
        "      xmin_corr = (xmin)\n",
        "      xmax_corr = (xmax)\n",
        "      ymin_corr = (ymin)\n",
        "      ymax_corr = (ymax)\n",
        "          \n",
        "      boxes.append([xmin_corr, ymin_corr, xmax_corr, ymax_corr])\n",
        "    \n",
        "\n",
        "\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "    #area = torch.as_tensor(area, dtype=torch.float32)\n",
        "    iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
        "    \n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"image_id\"] = torch.tensor([idx])\n",
        "    target[\"area\"] = area\n",
        "    target[\"iscrowd\"] = iscrowd\n",
        "    \n",
        "    if self.transforms:\n",
        "      sample = self.transforms(image = img,\n",
        "                                bboxes = target['boxes'],\n",
        "                                labels = labels)\n",
        "      img = sample['image']\n",
        "      target['boxes'] = torch.Tensor(sample['bboxes'])\n",
        "\n",
        "    return img, target\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.imgs)"
      ],
      "metadata": {
        "id": "V3Fo2gNUGb1S"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send train=True for training transforms and False for val/test transforms\n",
        "def get_transform(train):\n",
        "  if train:\n",
        "    return A.Compose(\n",
        "      [\n",
        "        A.HorizontalFlip(0.5),\n",
        "        # ToTensorV2 converts image to pytorch tensor without div by 255\n",
        "        ToTensorV2(p=1.0) \n",
        "      ],\n",
        "      bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}\n",
        "    )\n",
        "  else:\n",
        "    return A.Compose(\n",
        "      [ToTensorV2(p=1.0)],\n",
        "      bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}\n",
        "    )"
      ],
      "metadata": {
        "id": "CMBIlwdRShFx"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_dir = '/drive/MyDrive/CSE499 Project/Patch Datasets/Hamamatsu XR'\n",
        "test_dir = '/drive/MyDrive/CSE499 Project/Patch Datasets/Hamamatsu XR'"
      ],
      "metadata": {
        "id": "KDuLWW4lOH9p"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset =      MitosisImagesDataset(files_dir, 481, 451,transforms=get_transform(train=False))\n",
        "dataset_test = MitosisImagesDataset(files_dir, 481, 451,transforms=get_transform(train=False))"
      ],
      "metadata": {
        "id": "XubkG2cR6Pkr"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[28]"
      ],
      "metadata": {
        "id": "eknoiscY6RTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5f52f7-5c36-4f6e-f62a-9b064d679995"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.7922, 0.8314, 0.8667,  ..., 0.7961, 0.7216, 0.8039],\n",
              "          [0.7804, 0.8196, 0.8314,  ..., 0.7765, 0.7333, 0.7490],\n",
              "          [0.7882, 0.8078, 0.8157,  ..., 0.8314, 0.7725, 0.7608],\n",
              "          ...,\n",
              "          [0.8353, 0.8824, 0.9294,  ..., 0.7490, 0.8627, 0.7765],\n",
              "          [0.9059, 0.9020, 0.8863,  ..., 0.7098, 0.7294, 0.7686],\n",
              "          [0.9098, 0.8902, 0.8627,  ..., 0.7020, 0.7451, 0.7686]],\n",
              " \n",
              "         [[0.3490, 0.3647, 0.3804,  ..., 0.5216, 0.5686, 0.6863],\n",
              "          [0.3686, 0.3961, 0.3922,  ..., 0.5882, 0.5059, 0.5569],\n",
              "          [0.3922, 0.4000, 0.3961,  ..., 0.6196, 0.5294, 0.5333],\n",
              "          ...,\n",
              "          [0.6039, 0.6588, 0.7137,  ..., 0.4078, 0.4118, 0.4275],\n",
              "          [0.6667, 0.6588, 0.6431,  ..., 0.3216, 0.4000, 0.4235],\n",
              "          [0.6863, 0.6627, 0.6235,  ..., 0.3137, 0.3608, 0.3882]],\n",
              " \n",
              "         [[0.6549, 0.6784, 0.7098,  ..., 0.8078, 0.8157, 0.8902],\n",
              "          [0.7333, 0.7333, 0.7137,  ..., 0.6902, 0.7333, 0.8118],\n",
              "          [0.7529, 0.7333, 0.7176,  ..., 0.7451, 0.7216, 0.7608],\n",
              "          ...,\n",
              "          [0.8235, 0.8353, 0.8706,  ..., 0.7176, 0.6745, 0.6863],\n",
              "          [0.8392, 0.8196, 0.7961,  ..., 0.6745, 0.7333, 0.7216],\n",
              "          [0.8549, 0.8235, 0.7843,  ..., 0.6706, 0.7020, 0.6902]]]),\n",
              " {'area': tensor([13.8889]),\n",
              "  'boxes': tensor([[ 2.1333, 22.4167,  5.4667, 26.5833]]),\n",
              "  'image_id': tensor([28]),\n",
              "  'iscrowd': tensor([0]),\n",
              "  'labels': tensor([1])})"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =      MitosisImagesDataset(files_dir, 481, 451,transforms=get_transform(train=False))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_data_loader  = DataLoader(train_dataset,batch_size=10,shuffle=True,num_workers=4,collate_fn=utils.collate_fn)"
      ],
      "metadata": {
        "id": "XKrOjJhgxZdP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "-qPRofeYzrOa"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBuRsJ3X0uTn",
        "outputId": "400317b8-d8c8-44a8-9131-0fd2ccd1f19e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt \n",
        "\n",
        "# images,targets = next(iter(train_data_loader))\n",
        "# images = list(image.to(device) for image in images)\n",
        "# targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "\n",
        "# boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
        "# img = images[0].permute(1,2,0).cpu().numpy()\n",
        "# fig,ax = plt.subplots(1, 1, figsize=(50,30))\n",
        "\n",
        "# for box in boxes:\n",
        "#   cv2.rectangle(img,\n",
        "#                 (box[0],box[1]),\n",
        "#                 (box[2],box[3]),\n",
        "#                 (220,0,0), 1)\n",
        "\n",
        "# ax.set_axis_off()\n",
        "# ax.imshow(img)"
      ],
      "metadata": {
        "id": "EAQerS6L9ND3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes=2\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) "
      ],
      "metadata": {
        "id": "tLhwVd903q9f"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "k3_Mn0GmAJEw"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "_pU8uhDI3w4r"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itr = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for images,targets in train_data_loader:\n",
        "    images = list(image.to(device) for image in images)\n",
        "    targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "\n",
        "    loss_dict = model(images,targets)\n",
        "\n",
        "    losses = sum(loss for loss in loss_dict.values())\n",
        "    loss_value = losses.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if itr % 50 == 0:\n",
        "      print(f\"Iteration #{itr} loss: {loss_value}\")\n",
        "\n",
        "    itr+=1\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "  print(f\"Epoch #{epoch} loss: {loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVeM4q-K37xj",
        "outputId": "2a137e54-a986-4602-eea0-b821d18c59a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0 loss: 1.278481364250183\n",
            "Epoch #1 loss: 1.038503646850586\n",
            "Epoch #2 loss: 0.7167458534240723\n",
            "Epoch #3 loss: 1.0711729526519775\n",
            "Epoch #4 loss: 0.8949969410896301\n",
            "Epoch #5 loss: 0.8229814767837524\n",
            "Epoch #6 loss: 0.8153839707374573\n",
            "Epoch #7 loss: 0.9438090324401855\n",
            "Epoch #8 loss: 0.7520048022270203\n",
            "Iteration #50 loss: 1.083060622215271\n",
            "Epoch #9 loss: 1.083060622215271\n",
            "Epoch #10 loss: 0.8516127467155457\n",
            "Epoch #11 loss: 0.8825467824935913\n",
            "Epoch #12 loss: 1.0694729089736938\n",
            "Epoch #13 loss: 0.6851437091827393\n",
            "Epoch #14 loss: 1.135145664215088\n",
            "Epoch #15 loss: 0.8707451820373535\n",
            "Epoch #16 loss: 0.98777174949646\n",
            "Epoch #17 loss: 0.7367779016494751\n",
            "Epoch #18 loss: 0.7707308530807495\n",
            "Iteration #100 loss: 0.9232560396194458\n",
            "Epoch #19 loss: 0.9232560396194458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # training for one epoch\n",
        "    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    #evaluate(model, data_loader_test, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "TPUUbUbj1lXS",
        "outputId": "03695e01-029d-4c79-f4bf-27bffc548ad8"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-a94dfb842402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# training for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# update the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                      .format(degen_bb, target_idx))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/backbone_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/feature_pyramid_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0minner_top_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mlast_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_lateral\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minner_top_down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_from_layer_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_blocks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/feature_pyramid_network.py\u001b[0m in \u001b[0;36mget_result_from_layer_blocks\u001b[0;34m(self, x, idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 422.00 MiB (GPU 0; 15.90 GiB total capacity; 14.02 GiB already allocated; 397.75 MiB free; 14.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1bsTH5vJ2udK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/drive/MyDrive/CSE499 Project/modelSaves'"
      ],
      "metadata": {
        "id": "do0bu-pRs3xF",
        "outputId": "cefd124f-dbb4-4348-8ea0-089367c36fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/drive/.shortcut-targets-by-id/1M-kTVs7g43FucvCjcPvKwiR8r1e1qtHe/CSE499 Project/modelSaves\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "metadata": {
        "id": "Ee4TWXB-s86G",
        "outputId": "f0c1e789-3429-4ac8-dcf5-e6f0da45bf21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "torch.save({\n",
        "'epoch':epoch,\n",
        "'model_state_dict':model.state_dict(),\n",
        "'optimizer_state_dict':optimizer.state_dict(),\n",
        "},'ckpt.pth')"
      ],
      "metadata": {
        "id": "dyIUjkYUsQrB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/drive/MyDrive/CSE499 Project/Patch Datasets/Hamamatsu XR/001.tiff')\n",
        "image.shape"
      ],
      "metadata": {
        "id": "mYdXyghRu7lw",
        "outputId": "c7c92ee1-5b14-48ab-ae39-4d91e2877fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(451, 481, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = torchvision.transforms.ToTensor()(image)"
      ],
      "metadata": {
        "id": "dwgZK8NF72-J"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "BpFU14Lb8PFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "vOeuNwaS9GFT",
        "outputId": "2556cd2e-8ed8-42c8-b4c4-ce22235c1e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.9020, 0.9059, 0.9098,  ..., 0.8667, 0.8980, 0.8745],\n",
              "         [0.8824, 0.8980, 0.9176,  ..., 0.8471, 0.8667, 0.8588],\n",
              "         [0.8863, 0.9059, 0.9255,  ..., 0.8275, 0.8078, 0.8314],\n",
              "         ...,\n",
              "         [0.7725, 0.7882, 0.8000,  ..., 0.9647, 0.8980, 0.8941],\n",
              "         [0.7804, 0.7882, 0.7922,  ..., 0.9686, 0.8824, 0.8902],\n",
              "         [0.7569, 0.7647, 0.7843,  ..., 0.9647, 0.9216, 0.8510]],\n",
              "\n",
              "        [[0.8824, 0.8784, 0.8824,  ..., 0.7373, 0.7647, 0.7647],\n",
              "         [0.8706, 0.8706, 0.8784,  ..., 0.7176, 0.7137, 0.7373],\n",
              "         [0.8824, 0.8824, 0.8784,  ..., 0.7059, 0.6784, 0.6941],\n",
              "         ...,\n",
              "         [0.4824, 0.4980, 0.5176,  ..., 0.7843, 0.7961, 0.7569],\n",
              "         [0.4902, 0.4980, 0.5098,  ..., 0.8000, 0.8039, 0.7647],\n",
              "         [0.4706, 0.4784, 0.5059,  ..., 0.7804, 0.7725, 0.7608]],\n",
              "\n",
              "        [[0.9176, 0.9059, 0.9020,  ..., 0.8706, 0.8824, 0.9059],\n",
              "         [0.9059, 0.8980, 0.9020,  ..., 0.8510, 0.8392, 0.8824],\n",
              "         [0.8902, 0.9020, 0.9020,  ..., 0.8353, 0.8157, 0.8275],\n",
              "         ...,\n",
              "         [0.8275, 0.8431, 0.8706,  ..., 0.9529, 0.9373, 0.9529],\n",
              "         [0.8353, 0.8431, 0.8627,  ..., 0.9686, 0.9412, 0.9569],\n",
              "         [0.8078, 0.8157, 0.8431,  ..., 0.9608, 0.9373, 0.9333]]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(list(image))"
      ],
      "metadata": {
        "id": "mD5-RubY8Uz3",
        "outputId": "f52a08cd-c7f7-43eb-fa4e-59790048b400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b43c09b6250f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Check for degenerate boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 raise ValueError(\"images is expected to be a list of 3d tensors \"\n\u001b[0;32m--> 110\u001b[0;31m                                  \"of shape [C, H, W], got {}\".format(image.shape))\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: images is expected to be a list of 3d tensors of shape [C, H, W], got torch.Size([451, 481])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./model.pth'))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "_ng_I6SMF3w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MitosisImagesDataset(files_dir, 481, 451,transforms=get_transform(train=False))\n",
        "\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "\n",
        "test_split = 0.2\n",
        "tsize = int(len(test_dataset)*test_split)\n",
        "\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, indices[-tsize:])\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "  test_dataset,\n",
        "  batch_size=10,\n",
        "  shuffle=False,\n",
        "  num_workers=4,\n",
        "  collate_fn=utils.collate_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "rUq5rCuJXfq8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_data_loader, device=device)"
      ],
      "metadata": {
        "id": "fx_qQJYitko2",
        "outputId": "4cdc2463-c9d3-4e21-8bd2-f93a8e37d549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/10]  eta: 0:00:11  model_time: 0.5770 (0.5770)  evaluator_time: 0.0029 (0.0029)  time: 1.1222  data: 0.5313  max mem: 7973\n",
            "Test:  [ 9/10]  eta: 0:00:00  model_time: 0.5579 (0.5497)  evaluator_time: 0.0022 (0.0023)  time: 0.6300  data: 0.0691  max mem: 7973\n",
            "Test: Total time: 0:00:06 (0.6352 s / it)\n",
            "Averaged stats: model_time: 0.5579 (0.5497)  evaluator_time: 0.0022 (0.0023)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coco_eval.CocoEvaluator at 0x7f88309e84d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from coco_utils import get_coco_api_from_dataset\n",
        "from coco_eval import CocoEvaluator\n",
        "import time\n",
        "\n",
        "def _get_iou_types(model):\n",
        "    model_without_ddp = model\n",
        "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
        "        model_without_ddp = model.module\n",
        "    iou_types = [\"bbox\"]\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
        "        iou_types.append(\"segm\")\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
        "        iou_types.append(\"keypoints\")\n",
        "    return iou_types\n"
      ],
      "metadata": {
        "id": "Pe5NhN9vqvZy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    n_threads = torch.get_num_threads()\n",
        "    # FIXME remove this and make paste_masks_in_image run on the GPU\n",
        "    torch.set_num_threads(1)\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    model.eval()\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = \"Test:\"\n",
        "\n",
        "    coco = get_coco_api_from_dataset(data_loader.dataset)\n",
        "    iou_types = _get_iou_types(model)\n",
        "    coco_evaluator = CocoEvaluator(coco, iou_types)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
        "        images = list(img.to(device) for img in images)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        model_time = time.time()\n",
        "        outputs = model(images)\n",
        "\n",
        "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
        "        model_time = time.time() - model_time\n",
        "\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        evaluator_time = time.time()\n",
        "        coco_evaluator.update(res)\n",
        "        evaluator_time = time.time() - evaluator_time\n",
        "        metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    coco_evaluator.synchronize_between_processes()\n",
        "\n",
        "    # accumulate predictions from all images\n",
        "    coco_evaluator.accumulate()\n",
        "    coco_evaluator.summarize()\n",
        "    torch.set_num_threads(n_threads)\n",
        "    return coco_evaluator"
      ],
      "metadata": {
        "id": "ub0hvADTpsaf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model,test_data_loader,device)"
      ],
      "metadata": {
        "id": "Ilr9aW6Cq76v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_get_iou_types(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf2J5yI_rAqv",
        "outputId": "0ebdf70b-2b14-4ad8-e621-491ff814d74d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bbox']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric_logger = utils.MetricLogger(delimiter=\"  \")"
      ],
      "metadata": {
        "id": "QXkAfuJbsccM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "HaRfPP_Hu8Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,targets in metric_logger.log_every(test_data_loader, 20, \"Test:\"):\n",
        "  images = list(img.to(device) for img in images)\n",
        "  outputs = model(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "uhkDUBXqr7Hp",
        "outputId": "d1fade32-9517-486e-dadd-a27cf05c1372"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b9a9cdd3f9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                      .format(degen_bb, target_idx))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/backbone_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/feature_pyramid_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0minner_top_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mlast_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_lateral\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minner_top_down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_from_layer_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_blocks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/feature_pyramid_network.py\u001b[0m in \u001b[0;36mget_result_from_layer_blocks\u001b[0;34m(self, x, idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 422.00 MiB (GPU 0; 15.90 GiB total capacity; 14.02 GiB already allocated; 405.75 MiB free; 14.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5GMsYEKseeY",
        "outputId": "8a91034d-c621-4a89-edfd-cc173607ff7a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.6902, 0.6588, 0.6588,  ..., 0.4353, 0.4549, 0.5059],\n",
              "         [0.7020, 0.6431, 0.6471,  ..., 0.5020, 0.5098, 0.5569],\n",
              "         [0.6902, 0.6510, 0.6549,  ..., 0.5608, 0.5647, 0.6039],\n",
              "         ...,\n",
              "         [0.4392, 0.4353, 0.5059,  ..., 0.6235, 0.5294, 0.4275],\n",
              "         [0.4824, 0.4941, 0.5647,  ..., 0.6275, 0.5333, 0.4431],\n",
              "         [0.5020, 0.5647, 0.6314,  ..., 0.6118, 0.5176, 0.4353]],\n",
              "\n",
              "        [[0.4235, 0.4471, 0.4431,  ..., 0.3843, 0.3216, 0.2863],\n",
              "         [0.4627, 0.4431, 0.4431,  ..., 0.4353, 0.3804, 0.3451],\n",
              "         [0.4863, 0.4667, 0.4588,  ..., 0.4667, 0.4196, 0.3882],\n",
              "         ...,\n",
              "         [0.3333, 0.2863, 0.2824,  ..., 0.5216, 0.4745, 0.4157],\n",
              "         [0.3490, 0.3059, 0.3137,  ..., 0.5098, 0.4588, 0.4118],\n",
              "         [0.3529, 0.3255, 0.3412,  ..., 0.4863, 0.4353, 0.3961]],\n",
              "\n",
              "        [[0.7647, 0.7765, 0.7725,  ..., 0.6549, 0.6510, 0.6667],\n",
              "         [0.7765, 0.7373, 0.7373,  ..., 0.7098, 0.6902, 0.6902],\n",
              "         [0.7765, 0.7412, 0.7373,  ..., 0.7569, 0.7216, 0.7137],\n",
              "         ...,\n",
              "         [0.6510, 0.6745, 0.6627,  ..., 0.7765, 0.7176, 0.6314],\n",
              "         [0.6510, 0.6980, 0.6941,  ..., 0.7843, 0.7176, 0.6471],\n",
              "         [0.6471, 0.7294, 0.7294,  ..., 0.7725, 0.7059, 0.6431]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh1T9QZ4s9ah",
        "outputId": "9dad4cc4-5455-4fe0-f62d-52c2e40a347c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
              " 'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
              " 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JTehr_YRyuNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}